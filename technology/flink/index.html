<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Apache Flink Technology Summary"><meta name=author content="Jerome Boyer"><link href=https://ibm-cloud-architecture.github.com/refarch-eda/technology/flink/ rel=canonical><link href=../security/ rel=prev><link href=../spring/ rel=next><link rel=icon href=../../assets/favicon.png><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.17"><title>Apache Flink Technology Summary - IBM Automation - Event-driven Solution - Sharing knowledge</title><link rel=stylesheet href=../../assets/stylesheets/main.bcfcd587.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#why-flink class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="IBM Automation - Event-driven Solution - Sharing knowledge" class="md-header__button md-logo" aria-label="IBM Automation - Event-driven Solution - Sharing knowledge" data-md-component=logo> <img src=../../images/es-icon.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> IBM Automation - Event-driven Solution - Sharing knowledge </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Apache Flink Technology Summary </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ibm-cloud-architecture/refarch-eda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> ibm-cloud-architecture/refarch-eda </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="IBM Automation - Event-driven Solution - Sharing knowledge" class="md-nav__button md-logo" aria-label="IBM Automation - Event-driven Solution - Sharing knowledge" data-md-component=logo> <img src=../../images/es-icon.png alt=logo> </a> IBM Automation - Event-driven Solution - Sharing knowledge </label> <div class=md-nav__source> <a href=https://github.com/ibm-cloud-architecture/refarch-eda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> ibm-cloud-architecture/refarch-eda </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../news/ class=md-nav__link> <span class=md-ellipsis> What's new </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Introduction </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../introduction/overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../introduction/reference-architecture/ class=md-nav__link> <span class=md-ellipsis> Reference Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../introduction/usecases/ class=md-nav__link> <span class=md-ellipsis> Business Use Cases </span> </a> </li> <li class=md-nav__item> <a href=../../introduction/target-audiences/ class=md-nav__link> <span class=md-ellipsis> Target Audiences </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Learning Journey </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Learning Journey </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../journey/101/ class=md-nav__link> <span class=md-ellipsis> Get started (101 content) </span> </a> </li> <li class=md-nav__item> <a href=../../journey/201/ class=md-nav__link> <span class=md-ellipsis> Deeper dive (201 content) </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../concepts/terms-and-definitions/ class=md-nav__link> <span class=md-ellipsis> Terms & Definitions </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/integration/ class=md-nav__link> <span class=md-ellipsis> Agile Integration </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/events-versus-messages/ class=md-nav__link> <span class=md-ellipsis> Event streaming versus Queuing </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/fit-to-purpose/ class=md-nav__link> <span class=md-ellipsis> Fit for purpose </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/model/ class=md-nav__link> <span class=md-ellipsis> Devising the data models </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/flow-architectures/ class=md-nav__link> <span class=md-ellipsis> Flow Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/service-mesh/ class=md-nav__link> <span class=md-ellipsis> Service mesh </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Advantages of EDA </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Advantages of EDA </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../advantages/microservice/ class=md-nav__link> <span class=md-ellipsis> Microservice decoupling </span> </a> </li> <li class=md-nav__item> <a href=../../advantages/reactive/ class=md-nav__link> <span class=md-ellipsis> Reactive systems </span> </a> </li> <li class=md-nav__item> <a href=../../advantages/resiliency/ class=md-nav__link> <span class=md-ellipsis> Resiliency </span> </a> </li> <li class=md-nav__item> <a href=../../advantages/scalability/ class=md-nav__link> <span class=md-ellipsis> Scalability </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Patterns in EDA </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Patterns in EDA </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../patterns/intro/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/event-sourcing/ class=md-nav__link> <span class=md-ellipsis> Event Sourcing </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/cqrs/ class=md-nav__link> <span class=md-ellipsis> CQRS </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/saga/ class=md-nav__link> <span class=md-ellipsis> Saga </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/dlq/ class=md-nav__link> <span class=md-ellipsis> Dead Letter Queue </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/topic-replication/ class=md-nav__link> <span class=md-ellipsis> Topic Replication </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/data-pipeline/ class=md-nav__link> <span class=md-ellipsis> Data Intensive App </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/realtime-analytics/ class=md-nav__link> <span class=md-ellipsis> Near real-time analytics </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/api-mgt/ class=md-nav__link> <span class=md-ellipsis> API management </span> </a> </li> <li class=md-nav__item> <a href=../../patterns/cep/ class=md-nav__link> <span class=md-ellipsis> Situational decision </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Methodology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../methodology/event-storming/ class=md-nav__link> <span class=md-ellipsis> Event Storming </span> </a> </li> <li class=md-nav__item> <a href=../../methodology/domain-driven-design/ class=md-nav__link> <span class=md-ellipsis> Domain-Driven Design </span> </a> </li> <li class=md-nav__item> <a href=../../methodology/data-intensive/ class=md-nav__link> <span class=md-ellipsis> Data Intensive App Development </span> </a> </li> <li class=md-nav__item> <a href=../../methodology/data-lineage/ class=md-nav__link> <span class=md-ellipsis> Data lineage </span> </a> </li> <li class=md-nav__item> <a href=../../methodology/governance/ class=md-nav__link> <span class=md-ellipsis> Governance </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9 checked> <label class=md-nav__link for=__nav_9 id=__nav_9_label tabindex=0> <span class=md-ellipsis> Technology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_9_label aria-expanded=true> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Technology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../kafka-overview/ class=md-nav__link> <span class=md-ellipsis> Kafka Overview </span> </a> </li> <li class=md-nav__item> <a href=../event-streams/ class=md-nav__link> <span class=md-ellipsis> Event Streams </span> </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/eda-tech-academy/demo/ class=md-nav__link> <span class=md-ellipsis> Event Streams Demo Script </span> </a> </li> <li class=md-nav__item> <a href=../faq/ class=md-nav__link> <span class=md-ellipsis> Kafka FAQ </span> </a> </li> <li class=md-nav__item> <a href=../mq/ class=md-nav__link> <span class=md-ellipsis> MQ in EDA context </span> </a> </li> <li class=md-nav__item> <a href=../kafka-producers/ class=md-nav__link> <span class=md-ellipsis> Kafka Producers </span> </a> </li> <li class=md-nav__item> <a href=../kafka-consumers/ class=md-nav__link> <span class=md-ellipsis> Kafka Consumers </span> </a> </li> <li class=md-nav__item> <a href=../avro-schemas/ class=md-nav__link> <span class=md-ellipsis> Avro Schema </span> </a> </li> <li class=md-nav__item> <a href=../advanced-kafka/ class=md-nav__link> <span class=md-ellipsis> Advanced Concepts </span> </a> </li> <li class=md-nav__item> <a href=../kafka-streams/ class=md-nav__link> <span class=md-ellipsis> Kafka Streams </span> </a> </li> <li class=md-nav__item> <a href=../kafka-connect/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect </span> </a> </li> <li class=md-nav__item> <a href=../event-streams/es-maas/security/ class=md-nav__link> <span class=md-ellipsis> Kafka security </span> </a> </li> <li class=md-nav__item> <a href=../kafka-monitoring/ class=md-nav__link> <span class=md-ellipsis> Kafka Monitoring </span> </a> </li> <li class=md-nav__item> <a href=../kafka-mirrormaker/ class=md-nav__link> <span class=md-ellipsis> Mirror Maker 2 </span> </a> </li> <li class=md-nav__item> <a href=../security/ class=md-nav__link> <span class=md-ellipsis> Security </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Apache Flink </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Apache Flink </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-flink class=md-nav__link> <span class=md-ellipsis> Why Flink? </span> </a> </li> <li class=md-nav__item> <a href=#the-what class=md-nav__link> <span class=md-ellipsis> The What </span> </a> </li> <li class=md-nav__item> <a href=#flink-architecture class=md-nav__link> <span class=md-ellipsis> Flink architecture </span> </a> <nav class=md-nav aria-label="Flink architecture"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#batch-processing class=md-nav__link> <span class=md-ellipsis> Batch processing </span> </a> </li> <li class=md-nav__item> <a href=#high-availability class=md-nav__link> <span class=md-ellipsis> High Availability </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stream-processing-concepts class=md-nav__link> <span class=md-ellipsis> Stream processing concepts </span> </a> </li> <li class=md-nav__item> <a href=#stateless class=md-nav__link> <span class=md-ellipsis> Stateless </span> </a> </li> <li class=md-nav__item> <a href=#statefulness class=md-nav__link> <span class=md-ellipsis> Statefulness </span> </a> <nav class=md-nav aria-label=Statefulness> <ul class=md-nav__list> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State management </span> </a> </li> <li class=md-nav__item> <a href=#windowing class=md-nav__link> <span class=md-ellipsis> Windowing </span> </a> </li> <li class=md-nav__item> <a href=#trigger class=md-nav__link> <span class=md-ellipsis> Trigger </span> </a> </li> <li class=md-nav__item> <a href=#eviction class=md-nav__link> <span class=md-ellipsis> Eviction </span> </a> </li> <li class=md-nav__item> <a href=#watermark class=md-nav__link> <span class=md-ellipsis> Watermark </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spring/ class=md-nav__link> <span class=md-ellipsis> Spring cloud </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10> <label class=md-nav__link for=__nav_10 id=__nav_10_label tabindex=0> <span class=md-ellipsis> Use Cases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_10_label aria-expanded=false> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> Use Cases </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../use-cases/gitops/ class=md-nav__link> <span class=md-ellipsis> Event-driven solution GitOps </span> </a> </li> <li class=md-nav__item> <a href=../event-streams/es-cp4i/ class=md-nav__link> <span class=md-ellipsis> Deploy Event-Streams </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-s3/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect - S3 </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-cos/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect - COS </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-jdbc/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect - jdbc </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-mq/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect - MQ </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-rabbitmq/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect - Rabbitmq </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/kafka-streams/ class=md-nav__link> <span class=md-ellipsis> Kafka Streams labs </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/db2-debezium/ class=md-nav__link> <span class=md-ellipsis> DB2 - CDC Debezium - Outbox </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/kafka-mm2/ class=md-nav__link> <span class=md-ellipsis> Mirror maker 2 labs </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/schema-registry-on-cloud/ class=md-nav__link> <span class=md-ellipsis> Schema registry ES on Cloud </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/schema-registry-on-ocp/ class=md-nav__link> <span class=md-ellipsis> Schema registry </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/monitoring-on-cloud/ class=md-nav__link> <span class=md-ellipsis> Monitoring ES on Cloud </span> </a> </li> <li class=md-nav__item> <a href=../../use-cases/monitoring-on-ocp/ class=md-nav__link> <span class=md-ellipsis> Monitoring ES </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_11> <label class=md-nav__link for=__nav_11 id=__nav_11_label tabindex=0> <span class=md-ellipsis> Scenarios </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_11_label aria-expanded=false> <label class=md-nav__title for=__nav_11> <span class="md-nav__icon md-icon"></span> Scenarios </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../scenarios/overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/refarch-kc/ class=md-nav__link> <span class=md-ellipsis> Reefer Shipment Solution </span> </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/vaccine-solution-main/ class=md-nav__link> <span class=md-ellipsis> Vaccine at Scale </span> </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/eda-rt-inventory-gitops class=md-nav__link> <span class=md-ellipsis> Near real-time Inventory </span> </a> </li> <li class=md-nav__item> <a href=../../scenarios/saga-orchestration/ class=md-nav__link> <span class=md-ellipsis> SAGA with MQ Orchestration </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../additional-reading/ class=md-nav__link> <span class=md-ellipsis> Additional reading </span> </a> </li> <li class=md-nav__item> <a href=../../contribute/ class=md-nav__link> <span class=md-ellipsis> Contribute to this Site </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-flink class=md-nav__link> <span class=md-ellipsis> Why Flink? </span> </a> </li> <li class=md-nav__item> <a href=#the-what class=md-nav__link> <span class=md-ellipsis> The What </span> </a> </li> <li class=md-nav__item> <a href=#flink-architecture class=md-nav__link> <span class=md-ellipsis> Flink architecture </span> </a> <nav class=md-nav aria-label="Flink architecture"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#batch-processing class=md-nav__link> <span class=md-ellipsis> Batch processing </span> </a> </li> <li class=md-nav__item> <a href=#high-availability class=md-nav__link> <span class=md-ellipsis> High Availability </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stream-processing-concepts class=md-nav__link> <span class=md-ellipsis> Stream processing concepts </span> </a> </li> <li class=md-nav__item> <a href=#stateless class=md-nav__link> <span class=md-ellipsis> Stateless </span> </a> </li> <li class=md-nav__item> <a href=#statefulness class=md-nav__link> <span class=md-ellipsis> Statefulness </span> </a> <nav class=md-nav aria-label=Statefulness> <ul class=md-nav__list> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State management </span> </a> </li> <li class=md-nav__item> <a href=#windowing class=md-nav__link> <span class=md-ellipsis> Windowing </span> </a> </li> <li class=md-nav__item> <a href=#trigger class=md-nav__link> <span class=md-ellipsis> Trigger </span> </a> </li> <li class=md-nav__item> <a href=#eviction class=md-nav__link> <span class=md-ellipsis> Eviction </span> </a> </li> <li class=md-nav__item> <a href=#watermark class=md-nav__link> <span class=md-ellipsis> Watermark </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>Apache Flink</h1> <div class="admonition warning"> <p class=admonition-title>Warning</p> <p>Updated 08/20/2022- Work in progress</p> </div> <h2 id=why-flink>Why Flink?<a class=headerlink href=#why-flink title="Permanent link">&para;</a></h2> <p>In classical IT architecture, we can see two types of data processing: transactional and analytics. With 'monolytics' application, the database system serves multiple applications which sometimes access the same database instances and tables. This approach cause problems to support evolution and scaling. Microservice architecture addresses part of those problems by isolating data storage per service. </p> <p>To get insight from the data, the traditional approach is to develop data warehouse and ETL jobs to copy and transform data from the transactional systems to the warehouse. ETL process extracts data from a transactional database, transforms data into a common representation that might include validation, value normalization, encoding, deduplication, and schema transformation, and finally loads the new record into the target analytical database. They are batches and run periodically.</p> <p>From the data warehouse, the analysts build queries, metrics, and dashboards / reports to address a specific business question. Massive storage is needed, which uses different protocol such as: NFS, S3, HDFS...</p> <p>Today, there is a new way to think about data by seeing they are created as continuous streams of events, which can be processed in real time, and serve as the foundation for stateful stream processing application: the analytics move to the real data stream.</p> <p>We can define three classes of applications implemented with stateful stream processing:</p> <ol> <li><strong>Event-driven applications</strong>: to adopt the reactive manifesto for scaling, resilience, responsive application, leveraging messaging as communication system.</li> <li><strong>Data pipeline applications</strong>: replace ETL with low latency stream processing.</li> <li><strong>Data analytics applications</strong>: immediatly act on the data and query live updated reports. </li> </ol> <p>For more real industry use cases content see the <a href=https://www.flink-forward.org/ >Flink Forward web site.</a></p> <h2 id=the-what>The What<a class=headerlink href=#the-what title="Permanent link">&para;</a></h2> <p><a href=https://flink.apache.org>Apache Flink</a> (2016) is a framework and <strong>distributed processing</strong> engine for stateful computations over unbounded and bounded data streams. Flink supports batch (data set )and graph (data stream) processing. It is very good at:</p> <ul> <li>Very low latency processing event time semantics to get consistent and accurate results even in case of out of order events</li> <li>Exactly once state consistency </li> <li>Millisecond latencies while processing millions of events per second</li> <li>Expressive and easy-to-use APIs: map, reduce, join, window, split, and connect.</li> <li>SQL support to implement user friendly streaming queries</li> <li>Fault tolerance, and high availability: supports worker and master failover, eliminating any single point of failure</li> <li>A lot of connectors to integrate with Kafka, Cassandra, Elastic Search, JDBC, S3...</li> <li>Support container and deployment on Kubernetes</li> <li>Support updating the application code and migrate jobs to different Flink clusters without losing the state of the application</li> <li>Also support batch processing</li> </ul> <p>The figure below illustrates those different models combined with <a href=https://zeppelin.apache.org/ >Zepellin</a> as a multi purpose notebook to develop data analytic projects on top of Spark, Python or Flink.</p> <p><img alt="Flink components" src=images/arch.png width=width></p> <h2 id=flink-architecture>Flink architecture<a class=headerlink href=#flink-architecture title="Permanent link">&para;</a></h2> <p>Flink consists of a <strong>Job Manager</strong> and n <strong>Task Managers</strong>. </p> <p>The <strong>JobManager</strong> controls the execution of a single application. It receives an application for execution and builds a Task Execution Graph from the defined Job Graph. It manages job submission and the job lifecycle then allocates work to Task Managers The <strong>Resource Manager</strong> manages Task Slots and leverages underlying orchestrator, like Kubernetes or Yarn. A <strong>Task slot</strong> is the unit of work executed on CPU. The <strong>Task Managers</strong> execute the actual stream processing logic. There are multiple task managers running in a cluster. The number of slots limits the number of tasks a TaskManager can execute. After it has been started, a TaskManager registers its slots to the ResourceManager</p> <p><img alt src=images/flink-components.png width=width></p> <p>The <strong>Disparcher</strong> exposes API to submit applications for execution. It hosts the user interface too.</p> <p>Only one Job Manager is active at a given point of time, and there may be <code>n</code> Task Managers.</p> <p>There are different <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/ >deployment models</a>: </p> <ul> <li>Deploy on executing cluster, this is the <strong>session mode</strong>. Use <strong>session</strong> cluster to run multiple jobs: we need a JobManager container. </li> <li><strong>Per job</strong> mode, spin up a cluster per job submission. More k8s oriented. This provides better resource isolation. </li> <li><strong>Application mode</strong> creates a cluster per app with the main() function executed on the JobManager. It can include multiple jobs but they run inside the app. It allows for saving the required CPU cycles, but also save the bandwidth required for downloading the dependencies locally.</li> </ul> <p>Flink can run on any common resource manager like Hadoop Yarn, Mesos, or Kubernetes. For development purpose, we can use docker images to deploy a <strong>Session</strong> or <strong>Job cluster</strong>.</p> <h3 id=batch-processing>Batch processing<a class=headerlink href=#batch-processing title="Permanent link">&para;</a></h3> <p>Process all the data in one job with bounded dataset. It is used when we need all the data for assessing trend, develop AI model, and with a focus on throughput instead of latency.</p> <p>Hadoop was designed to do batch processing. Flink has capability to replace Hadoop map reduce processing.</p> <h3 id=high-availability>High Availability<a class=headerlink href=#high-availability title="Permanent link">&para;</a></h3> <p>With Task managers running in parallel, if one fails the number of available slots drops by the JobManager asks the Resource Manager to get new processing slots. The application's restart strategy determines how often the JobManager restarts the application and how long it waits between restarts.</p> <p>Flink uses Zookeeper to manage multiple JobManagers and select the leader to control the execution of the streaming application. Application's tasks checkpoints and other states are saved in a remote storage, but metadata are saved in Zookeeper. When a JobManager fails, all tasks that belong to its application are automatically cancelled. A new JobManager that takes over the work by getting information of the storage from Zookeeper, and then restarts the process with the JobManager.</p> <h2 id=stream-processing-concepts>Stream processing concepts<a class=headerlink href=#stream-processing-concepts title="Permanent link">&para;</a></h2> <p>In <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/#stream-processing>Flink</a>, applications are composed of streaming dataflows that may be transformed by user-defined operators. These dataflows form directed graphs that start with one or more sources, and end in one or more sinks. The data flows between operations. The figure below, from product documentation, summarizes the simple APIs used to develop a data stream processing flow:</p> <p><img alt=1 src=https://ci.apache.org/projects/flink/flink-docs-release-1.12/fig/program_dataflow.svg></p> <p><em>src: apache Flink product doc</em></p> <p>Stream processing includes a set of functions to transform data, to produce a new output stream. Intermediate steps compute rolling aggregations like min, max, mean, or collect and buffer records in time window to compute metrics on finite set of events. To properly define window operator semantics, we need to determine both how events are assigned to buckets and how often the window produces a result. Flink's streaming model is based on windowing and checkpointing, it uses controlled cyclic dependency graph as its execution engine.</p> <p>The following figure is showing integration of stream processing runtime with an append log system, like Kafka, with internal local state persistence and continuous checkpoint to remote storage as HA support:</p> <p><img alt src=images/flink-rt-processing.png width=width></p> <p>As part of the checkpointing process, Flink saves the 'offset read commit' information of the append log, so in case of a failure, Flink recovers a stateful streaming application by restoring its state from a previous checkpoint and resetting the read position on the append log.</p> <p>The evolution of microservice is to become more event-driven, which are stateful streaming applications that ingest event streams and process the events with application-specific business logic. This logic can be done in flow defined in Flink and executed in the clustered runtime.</p> <p><img alt src=images/evt-app.png width=width></p> <p>A lot of predefined connectors exist to connect to specific source and sink. Transform operators can be chained. Dataflow can consume from Kafka, Kinesis, Queue, and any data sources. A typical high level view of Flink app is presented in figure below:</p> <p><img alt=2 src=https://ci.apache.org/projects/flink/flink-docs-release-1.12/fig/flink-application-sources-sinks.png></p> <p><em>src: apache Flink product doc</em></p> <p>Programs in Flink are inherently parallel and distributed. During execution, a stream has one or more stream partitions, and each operator has one or more operator subtasks.</p> <p><img alt=3 src=https://ci.apache.org/projects/flink/flink-docs-release-1.12/fig/parallel_dataflow.svg></p> <p><em>src: apache Flink site</em></p> <p>A Flink application, can be stateful, run in parallel on a distributed cluster. The various parallel instances of a given operator will execute independently, in separate threads, and in general will be running on different machines. State is always accessed local, which helps Flink applications achieve high throughput and low-latency. You can choose to keep state on the JVM heap, or if it is too large, saves it in efficiently organized on-disk data structures.</p> <p><img alt=4 src=https://ci.apache.org/projects/flink/flink-docs-release-1.12/fig/local-state.png></p> <p>This is the Job Manager component which parallelizes the job and distributes slices of <a href=https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html>the Data Stream</a> flow, you defined, to the Task Managers for execution. Each parallel slice of your job will be executed in a <strong>task slot</strong>.</p> <p><img alt=5 src=https://ci.apache.org/projects/flink/flink-docs-release-1.12/fig/distributed-runtime.svg></p> <p>Once Flink is started (for example with the docker image), Flink Dashboard <a href=http://localhost:8081/#/overview>http://localhost:8081/#/overview</a> presents the execution reporting of those components:</p> <p><img alt=6 src=images/flink-dashboard.png width=width></p> <p>The execution is from one of the training examples, the number of task slot was set to 4, and one job is running.</p> <p>Spark is not a true real time processing while Flink is. Flink and Spark support batch processing too. </p> <h2 id=stateless>Stateless<a class=headerlink href=#stateless title="Permanent link">&para;</a></h2> <p>Some applications support data loss and expect fast recovery times in case of failure and always consuming the latest incoming data. Alerting applications where only low latency alerts are useful, or application where only the last data received is relevant. </p> <p>When checkpointing is turned off Flink offers no inherent guarantees in case of failures. This means that you can either have data loss or duplicate messages combined always with a loss of application state.</p> <h2 id=statefulness>Statefulness<a class=headerlink href=#statefulness title="Permanent link">&para;</a></h2> <p>When using aggregates or windows operators, states need to be kept. For fault tolerant Flink uses checkpoints and savepoints. Checkpoints represent a snapshot of where the input data stream is with each operator's state. A streaming dataflow can be resumed from a checkpoint while maintaining consistency (exactly-once processing semantics) by restoring the state of the operators and by replaying the records from the point of the checkpoint.</p> <p>In case of failure of a parallel execution, Flink stops the stream flow, then restarts operators from the last checkpoints. When doing the reallocation of data partition for processing, states are reallocated too. States are saved on distributed file systems. When coupled with Kafka as data source, the committed read offset will be part of the checkpoint data.</p> <p>Flink uses the concept of <code>Checkpoint Barriers</code>, which represents a separation of records, so records received since the last snapshot are part of the future snapshot. Barrier can be seen as a mark, a tag in the data stream that close a snapshot. </p> <p><img alt=Checkpoints src=images/checkpoints.png width=width></p> <p>In Kafka, it will be the last committed read offset. The barrier flows with the stream so can be distributed. Once a sink operator (the end of a streaming DAG) has received the <code>barrier n</code> from all of its input streams, it acknowledges that <code>snapshot n</code> to the checkpoint coordinator. After all sinks have acknowledged a snapshot, it is considered completed. Once <code>snapshot n</code> has been completed, the job will never ask the source for records before such snapshot.</p> <p>State snapshots are save in a state backend (in memory, HDFS, RockDB). </p> <p>KeyedStream is a key-value store. Key match the key in the stream, state update does not need transaction.</p> <p>For DataSet (Batch processing) there is no checkpoint, so in case of failure the stream is replayed. When addressing exactly once processing it is very important to consider the following:</p> <ol> <li>the read from the source</li> <li>apply the processing logic like window aggregation</li> <li>generate the results to a sink</li> </ol> <p>1 and 2 can be done exactly once, using Flink source connector and checkpointing but generating one unique result to a sink is more complex and is dependant of the target technology. </p> <p><img alt src=images/e2e-1.png width=width></p> <p>After reading records from Kafka, do the processing and generate results, in case of failure Flink will reload the record from the read offset and may generate duplicate in the Sink. </p> <p><img alt src=images/e2e-2.png width=width></p> <p>As duplicates will occur, we always need to assess idempotent support from downstream applications. A lot of distributed key-value storages support consistent result event after retries.</p> <p>To support end-to-end exactly one delivery we need to have a sink that supports transaction and two-phase commit. In case of failure we need to rollback the output generated. It is important to note transactional output impacts latency.</p> <p>Flink takes checkpoints periodically, like every 10 seconds, which leads to the minimum latency we can expect at the sink level.</p> <p>For Kafka Sink connector, as kafka producer, we need to set the <code>transactionId</code>, and the delivery type:</p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=k>new</span><span class=w> </span><span class=n>KafkaSinkBuilder</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span><span class=p>()</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=w>    </span><span class=p>.</span><span class=na>setBootstrapServers</span><span class=p>(</span><span class=n>bootstrapURL</span><span class=p>)</span>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=w>    </span><span class=p>.</span><span class=na>setDeliverGuarantee</span><span class=p>(</span><span class=n>DeliveryGuarantee</span><span class=p>.</span><span class=na>EXACTLY_ONCE</span><span class=p>)</span>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=w>    </span><span class=p>.</span><span class=na>setTransactionalIdPrefix</span><span class=p>(</span><span class=s>&quot;store-sol&quot;</span><span class=p>)</span>
</code></pre></div> <p>With transaction ID, a sequence number is sent by the kafka producer API to the broker, and so the partition leader will be able to remove duplicate retries.</p> <p><img alt src=images/e2e-3.png></p> <p>When the checkpointing period is set, we need to also configure <code>transaction.max.timeout.ms</code> of the Kafka broker and <code>transaction.timeout.ms</code> for the producer (sink connector) to a higher timeout than the checkpointing interval plus the max expected Flink downtime. If not the Kafka broker will consider the connection has fail and will remove its state management.</p> <h3 id=state-management>State management<a class=headerlink href=#state-management title="Permanent link">&para;</a></h3> <ul> <li>All data maintained by a task and used to compute the results of a function belong to the state of the task.</li> <li>While processing the data, the task can read and update its state and compute its result based on its input data and state.</li> <li>State management includes address very large states, and no state is lost in case of failures.</li> <li>Each operator needs to register its state.</li> <li><strong>Operator State</strong> is scoped to an operator task: all records processed by the same parallel task have access to the same state</li> <li><strong>Keyed state</strong> is maintained and accessed with respect to a key defined in the records of an operator’s input stream. Flink maintains one state instance per key value and Flink partitions all records with the same key to the operator task that maintains the state for this key. The key-value map is sharded across all parallel tasks:</li> </ul> <p><img alt src=images/key-state.png></p> <ul> <li>Each task maintains its state locally to improve latency. For small state, the state backends will use JVM heap, but for larger state RocksDB is used. A <strong>state backend</strong> takes care of checkpointing the state of a task to a remote and persistent storage.</li> <li>With stateful distributed processing, scaling stateful operators, enforces state repartitioning and assigning to more or fewer parallel tasks. Keys are organized in key-groups, and key groups are assigned to tasks. Operators with operator list state are scaled by redistributing the list entries. Operators with operator union list state are scaled by broadcasting the full list of state entries to each task.</li> </ul> <p>Flink uses <strong>Checkpointing</strong> to periodically store the state of the various stream processing operators on durable storage. </p> <p><img alt src=images/checkpoint.png></p> <p>When recovering from a failure, the stream processing job can resume from the latest checkpoint. </p> <p><img alt src=images/recover-checkpoint.png></p> <p>Checkpointing is coordinated by the Job Manager, it knows the location of the latest completed checkpoint which will get important later on. This checkpointing and recovery mechanism can provide exactly-once consistency for application state, given that all operators checkpoint and restore all of their states and that all input streams are reset to the position up to which they were consumed when the checkpoint was taken. This will work perfectly with Kafka, but not with sockets or queues where messages are lost once consumed. Therefore exactly-once state consistency can be ensured only if all input streams are from resettable data sources.</p> <p>During the recovery and depending on the sink operators of an application, some result records might be emitted multiple times to downstream systems.</p> <h3 id=windowing>Windowing<a class=headerlink href=#windowing title="Permanent link">&para;</a></h3> <p><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/windows.html>Windows</a> are buckets within a Stream and can be defined with times, or count of elements.</p> <ul> <li><strong>Tumbling</strong> window assign events into nonoverlapping buckets of fixed size. When the window border is passed, all the events are sent to an evaluation function for processing. Count-based tumbling windows define how many events are collected before triggering evaluation. Time based timbling window define time interval of n seconds. Amount of the data vary in a window. <code>.keyBy(...).window(TumblingProcessingTimeWindows.of(Time.seconds(2)))</code></li> </ul> <p><img alt src=images/tumbling.png></p> <ul> <li><strong>Sliding</strong> window: same but windows can overlap. An event might belong to multiple buckets. So there is a <code>window sliding time</code> parameter: <code>.keyBy(...).window(SlidingProcessingTimeWindows.of(Time.seconds(2), Time.seconds(1)))</code></li> </ul> <p><img alt src=images/sliding.png></p> <ul> <li><strong>Session</strong> window: Starts when the data stream processes records and stop when there is inactivity, so the timer set this threshold: <code>.keyBy(...).window(ProcessingTimeSessionWindows.withGap(Time.seconds(5)))</code>. The operator creates one window for each data element received.</li> </ul> <p><img alt src=images/session.png></p> <ul> <li> <p><strong>Global</strong> window: one window per key and never close. The processing is done with Trigger:</p> <div class=highlight><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=p>.</span><span class=na>keyBy</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
<a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=p>.</span><span class=na>window</span><span class=p>(</span><span class=n>GlobalWindows</span><span class=p>.</span><span class=na>create</span><span class=p>())</span>
<a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=p>.</span><span class=na>trigger</span><span class=p>(</span><span class=n>CountTrigger</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span>
</code></pre></div> </li> </ul> <p>KeyStream can help to run in parallel, each window will have the same key.</p> <p>Time is central to the stream processing, and the time is a parameter of the flow / environment and can take different meanings:</p> <ul> <li><code>ProcessingTime</code> = system time of the machine executing the task: best performance and low latency</li> <li><code>EventTime</code> = the time at the source level, embedded in the record. Deliver consistent and deterministic results regardless of order </li> <li><code>IngestionTime</code> = time when getting into Flink. </li> </ul> <p>See example <a href=https://github.com/jbcodeforce/flink-studies/blob/master/my-flink/src/main/java/jbcodeforce/windows/TumblingWindowOnSale.java>TumblingWindowOnSale.java</a> and to test it, do the following:</p> <div class=highlight><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Start the SaleDataServer that starts a server on socket 9181 and will read the avg.txt file and send each line to the socket</span>
<a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>java<span class=w> </span>-cp<span class=w> </span>target/my-flink-1.0.0-SNAPSHOT.jar<span class=w> </span>jbcodeforce.sale.SaleDataServer
<a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=c1># inside the job manager container start with </span>
<a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=sb>`</span>flink<span class=w> </span>run<span class=w> </span>-d<span class=w> </span>-c<span class=w> </span>jbcodeforce.windows.TumblingWindowOnSale<span class=w> </span>/home/my-flink/target/my-flink-1.0.0-SNAPSHOT.jar<span class=sb>`</span>.
<a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=c1># The job creates the data/profitPerMonthWindowed.txt file with accumulated sale and number of record in a 2 seconds tumbling time window</span>
<a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=o>(</span>June,Bat,Category5,154,6<span class=o>)</span>
<a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=o>(</span>August,PC,Category5,74,2<span class=o>)</span>
<a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=o>(</span>July,Television,Category1,50,1<span class=o>)</span>
<a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=o>(</span>June,Tablet,Category2,142,5<span class=o>)</span>
<a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=o>(</span>July,Steamer,Category5,123,6<span class=o>)</span>
<a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>...
</code></pre></div> <h3 id=trigger>Trigger<a class=headerlink href=#trigger title="Permanent link">&para;</a></h3> <p><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.13/dev/stream/operators/windows.html#triggers>Trigger</a> determines when a window is ready to be processed. All windows have default trigger. For example tumbling window has a 2s trigger. Global window has explicit trigger. We can implement our own triggers by implementing the Trigger interface with different methods to implement: onElement(..), onEventTime(...), onProcessingTime(...)</p> <p>Default triggers:</p> <ul> <li>EventTimeTrigger: fires based upon progress of event time</li> <li>ProcessingTimeTrigger: fires based upon progress of processing time</li> <li>CountTrigger: fires when # of element in a window &gt; parameter</li> <li>PurgingTrigger</li> </ul> <h3 id=eviction>Eviction<a class=headerlink href=#eviction title="Permanent link">&para;</a></h3> <p>Evictor is used to remove elements from a window after the trigger fires and before or after the window function is applied. The logic to remove is app specific.</p> <p>The predefined evictors: CountEvictor, DeltaEvictor and TimeEvictor.</p> <h3 id=watermark>Watermark<a class=headerlink href=#watermark title="Permanent link">&para;</a></h3> <p><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.13/dev/event_timestamps_watermarks.html>Watermark</a> is the mechanism to keep how the event time has progressed: with windowing operator, event time stamp is used, but windows are defined on elapse time, for example, 10 minutes, so watermark helps to track te point of time where no more delayed events will arrive. The Flink API expects a WatermarkStrategy that contains both a TimestampAssigner and WatermarkGenerator. A TimestampAssigner is a simple function that extracts a field from an event. A number of common strategies are available out of the box as static methods on WatermarkStrategy, so reference to the documentation and examples.</p> <p>Watermark is crucial for out of order events, and when dealing with multi sources. Kafka topic partitions can be a challenge without watermark. With IoT device and network latency, it is possible to get an event with an earlier timestamp, while the operator has already processed such event timestamp from other sources.</p> <p>It is possible to configure to accept late events, with the <code>allowed lateness</code> time by which element can be late before being dropped. Flink keeps a state of Window until the allowed lateness time expires.</p> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">&para;</a></h2> <ul> <li><a href=https://flink.apache.org/flink-architecture.html>Product documentation</a>. </li> <li><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/ >Official training</a></li> <li>Base docker image is: <a href=https://hub.docker.com/_/flink>https://hub.docker.com/_/flink</a></li> <li><a href=https://ci.apache.org/projects/flink/flink-docs-master/ops/deployment/docker.html>Flink docker setup</a> and the docker-compose files in this repo.</li> <li><a href=https://wints.github.io/flink-web/faq.html>FAQ</a></li> <li><a href=https://github.com/cloudera/flink-tutorials/tree/master/flink-stateful-tutorial>Cloudera flink stateful tutorial</a>: very good example for inventory transaction and queries on item considered as stream</li> <li><a href=https://www.elastic.co/blog/building-real-time-dashboard-applications-with-apache-flink-elasticsearch-and-kibana>Building real-time dashboard applications with Apache Flink, Elasticsearch, and Kibana</a></li> <li>Udemy Apache Flink a real time hands-on: do not recommend this one !.</li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2022 IBM </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/ibm-cloud-architecture target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/agileitarchitecture target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tooltips", "navigation.instant", "navigation.tabs.sticky", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.1e8ae164.min.js></script> </body> </html>